\documentclass[a4paper,10pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage[all]{xy}
\usepackage{graphicx}
%\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}
\usepackage{listings}
\usepackage{MnSymbol}

%\setlength{\parindent}{0in}

\newcounter{counter1}

\theoremstyle{plain}
\newtheorem{myteo}[counter1]{Teorema}
\newtheorem{mylem}[counter1]{Lemma}
\newtheorem{mypro}[counter1]{Proposizione}
\newtheorem{mycor}[counter1]{Corollario}
\newtheorem*{myteo*}{Teorema}
\newtheorem*{mylem*}{Lemma}
\newtheorem*{mypro*}{Proposizione}
\newtheorem*{mycor*}{Corollario}

\theoremstyle{definition}
\newtheorem{mydef}[counter1]{Definizione}
\newtheorem{myes}[counter1]{Esempio}
\newtheorem{myex}[counter1]{Esercizio}
\newtheorem*{mydef*}{Definizione}
\newtheorem*{myes*}{Esempio}
\newtheorem*{myex*}{Esercizio}

\theoremstyle{remark}
\newtheorem{mynot}[counter1]{Nota}
\newtheorem{myoss}[counter1]{Osservazione}
\newtheorem*{mynot*}{Nota}
\newtheorem*{myoss*}{Osservazione}


\newcommand{\obar}[1]{\overline{#1}}
\newcommand{\ubar}[1]{\underline{#1}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\ang}[1]{\left<#1\right>}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}

\newcommand{\der}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pder}[2]{\pfrac{\partial #1}{\partial #2}}
\newcommand{\sder}[2]{\sfrac{\partial #1}{\partial #2}}
\newcommand{\psder}[2]{\psfrac{\partial #1}{\partial #2}}

\newcommand{\intl}{\int \limits}

\DeclareMathOperator{\de}{d}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\len}{len}

\DeclareMathOperator{\gl}{GL}
\DeclareMathOperator{\aff}{Aff}
\DeclareMathOperator{\isom}{Isom}

\DeclareMathOperator{\im}{Im}




\title{Relazione laboratorio 3 (quello di matematica)}
\author{Enrico Polesel}
\date{\today}

\begin{document}
\maketitle

\lstset{language=Matlab,frame=single}

\section{Problema diretto}

Il problema diretto viene risolto con la funzione
\begin{lstlisting}
function [Lambda,Y] = directSLP(q,L,N)
\end{lstlisting}
dove vogliamo risolvere il problema diretto con potenziale $q$
sull'intervallo $[-L,L]$ discretizzando su una griglia di $N+1$
punti. La funzione ritorna il vettore degli autovalori $\Lambda$ e
matrice $Y$ tale che la colonna $i$-esima rappresenta l'autofunzione
corrispondente all'autovalore $i$-esimo calcolata nei punti griglia. 

Il primo passo è riscalare il potenziale dall'intervallo $[-L,L]$
all'intervallo $[0,2\pi ]$ e poi calcolarlo su una griglia di $N+1$
punti equispaziati sull'intervallo.
\begin{lstlisting}
  v = @(xi) (L/pi)^2 * feval(q,(L/pi)*(xi - pi )) ;
  V = feval(v, linspace (0, 2*pi, N+1) ) ;
\end{lstlisting}

L'ultimo ingrediente che ci manca per poter risolvere il problema è la
matrice $D^{(2)}$ che, dati i valori di una funzione $y$ nei punti
griglia, ne resistuisce i valori di $y^{(2)}$ nei punti
griglia. Questa matrice viene calcolata nella funzione
\begin{lstlisting}
  function D = directSLP_inner2(N)
\end{lstlisting}
usando le formule (11) e (12) dell'articolo.

A questo punto va scritta (e risolta) la matrice che discretizza il
problema continuo agl'autovalori. Questo viene delegato\footnote{la
  scelta di dividere questo codice deriva dal fatto che viene
  riutilizzato nella funzione per risolvere il problema inverso} alla
funzione
\begin{lstlisting}
  function [ E, Y] = directSLP_inner1(D,V)
\end{lstlisting}
che, data la matrice di differenziazione \lstinline{D} (che
nell'articolo viene chiamata $D^{(2)}$) e il potenziale calcolato nei
punti \lstinline{V}, ritorna gli autovalori \lstinline{E} (\textbf{non}
riscalati a $[-L,L]$) e il valore delle autofunzioni nei punti griglia
\lstinline{Y}.

La funzione \lstinline{directSLP_inner1}, dopo aver escluso i valori
ai bordi $0,2\pi$ (perché usiamo condizioni al contorno di Dirichlet)
costruisce la matrice $M$ e ne calcola autovalori e autovettori
utilizzando la funzione \lstinline{eig} di MATLAB.

L'ultima operazione che rimane da fare su \lstinline{directSLP} è
riscalare autovalori.


\section{Problema inverso}

Per risolvere il problema inverso aggiungiamo l'ipotesi che il
potenziale, definito su $[-L,L]$ deve essere simmetrico rispetto a
$0$. 

Prendiamo in ingresso $M$ autovalori e ci proponiamo di risolvere il
problema trovando il valore del potenziale su una griglia di $N +1 =
2M+2$ punti esclusi i punti estremi (per motivi che saranno chiariti
in seguito).

Di nuovo rimappiamo il problema su $[0,2\pi]$, fissiamo la griglia
$\xi _0, \xi _1, ..., \xi _N$ con $\xi _i = \frac{2\pi}{N}i$ e
chiamiamo $v(\xi)$ il potenziale rimappato.

Riscrivendo il problema diretto
\begin{equation*}
  D^{(2)} \begin{pmatrix}
    y_0 \\
    y_1 \\
    \vdots \\
    y_M \\
    y_{M+1} \\
    \vdots \\
    y _{2M} \\
    y _{2M+1} 
  \end{pmatrix} 
 + \begin{pmatrix}
    v(\xi _0) \\
    & v(\xi _1) \\
    & & \ddots  \\
    & & & v(\xi _M) \\
    & & & & v(\xi _{M+1}) \\
    & & & & & \ddots \\
    & & & & & & v( \xi _ {2M} ) \\
    & & & & & & & v(\xi _{2M+1}) 
    \end{pmatrix}
    \begin{pmatrix}
    y_0 \\
    y_1 \\
    \vdots \\
    y_M \\
    y_{M+1} \\
    \vdots \\
    y _{2M} \\
    y _{2M+1} 
  \end{pmatrix}
  = \lambda y
\end{equation*}
osseviamo che, essendo $y_0 = y_{2M+1} = 0$ (perché abbiamo fissato
condizioni al contorno di Dirichlet), nella relazione non compaiono i
valori di $v(\xi _0)$ e $v(\xi _{2M+1})$. Per simmetria abbiamo $v(\xi
_i) = v(\xi _{2M+1-i})$, quindi il vettore incognito del nostro
probelma è
\[
v = 
\begin{pmatrix}
  v_1 \\
  v_2 \\
  \vdots \\
  v_M 
\end{pmatrix}
=
\begin{pmatrix}
  v(\xi _1) \\
  v(\xi _2) \\
  \vdots \\
  v(\xi _M )
\end{pmatrix}
\]

Per passare da questo vettore ridotto al vettore ``completo'' si può
usare la matrice \lstinline{extender} così definita
\begin{lstlisting}
  extender = [ 
               zeros(1,M) ; 
               eye(M) ;
               flipud(eye(M)) ;
               zeros(1,M)
             ];
\end{lstlisting}
\begin{equation*}
  \lstinline{extender} =
  \begin{pmatrix}
    0 & & 0 \\
    1 & & 0 \\
    & \ddots & \\
    0 & & 1 \\
    0 & & 1 \\
    & \udots & \\
    1 & &0 \\
    0 & & 0\\
  \end{pmatrix}
\end{equation*}

Vediamo ora come è stata implementata la funzione per risolvere il
probelma inverso.

La funzione per calcolare il problema inverso è:
\begin{lstlisting}
  function q=inverseSLP(L,Lambda,Kmax,tol,v0)
\end{lstlisting}
dove \lstinline{L} è il limite dell'intervallo, \lstinline{Lambda} è
il vettore dei primi $M$ autovalori (ordinati in ordine decrescente),
\lstinline{Kmax} è il massimo numero di iterazioni da eseguire,
\lstinline{tol} è la tolleranza entro la quale si considera che la
soluzione ha raggiunto un punto fisso. \lstinline{v0} è un parametro
opzionale e rappresenta il potenziale iniziale da cui partire.

\subsection{Implementazione: preliminari}

Dopo aver incluso le librerie (\lstinline{regu} e
\lstinline{dmsuite}), la funzione imposta (se non è stato passato come
argomento) il potenziale iniziale a $0$, riscala il problema da
$[-L,L]$ trasformando gli autovalori e calcola i punti griglia.

Vengono precalcolate le seguenti matrici:
\begin{itemize}
\item La matrice di differenziazione $D^{(2)}$ che viene salvata in
  \lstinline{D}
\item La matrice \lstinline{extender} che estende il potenziale per
  simmetria
\item La matrice di penalizzazione \lstinline{PenMat}
\end{itemize}

Le prime due matrici sono semplici da costruire, per la prima basta
usare la funzione \lstinline{directSLP_inner2} e per la seconda la
  costruzione è già stata illustrata precedentemente.

Per la terza si utilizza la funzione
\lstinline{hermite_differentation_matrix}.

Prima di entrare nel ciclo vengongo inizializzate le variabili fra cui
il vettore del potenziale candidato \lstinline{vk} e la variabile di
conteggio cicli.

\subsection{Implementazione: \lstinline{hermite_differentation_matrix}}

La funzione
\begin{lstlisting}
  function D2 = hermite_differentation_matrix(N)
\end{lstlisting}
viene utilizzata per calcolare la matrice di differenziazione di
Hermite del second'ordine.

Per prima cosa vengono calcolate le radici dei polinomi di Hermite
calcolando gli autovalori (opportunamente riscalati di $\sqrt{2}$)
della matrice
\begin{equation*}
  \begin{pmatrix}
    0 & \sqrt{1} & 0 & \dots & 0 \\
    \sqrt{1} & 0 & \sqrt{2} & \ddots & \vdots \\
    0 & \sqrt{2} & \ddots & \ddots & 0 \\
    \vdots & \ddots & \ddots & 0 & \sqrt{N} \\
    0 & \dots & 0 & \sqrt{N} & 0
  \end{pmatrix}
\end{equation*}

Visto che nelle formule per le derivate compaiono i termini $t_i -t_j$
viene calcolata una matrice \lstinline{minus} tale che
\[ \lstinline{minus} _{i,j} = t_i - t_j \]

Viene calcolata anche versione leggermente modificata
\lstinline{minusplus}, che differisce da \lstinline{minus} perché gli
zeri sulla diagonale di quest'ultima sono stati sostituiti da $1$ in
modo da poter calcolare più agevolmente i prodotti.

Per calcolare la matrice di differenziazione abbiamo bisogno di
conoscere le derivate prime, seconde e terze dei polinomi di Lagrange
centrati nelle radici di Hermite calcolate nei punti griglia.

Il calcolo della derivata prima è facile usando la formula:
\[ \pi ' (t_j) = \prod _{i\neq j} \pa{t_j - t_i} \]
che si trasforma in un prodotto per righe di \lstinline{minusplus}

La derivata seconda è data da:
\[ \pi'' (t_j) = 2 \sum _{i\neq j} \prod _{
    h\neq j, h\neq i
  } (t_j - t_h)
\]

Il calcolo viene eseguito facendo variare $i\in 1,...,N$ e sommando
ogni volta al risultato il prodotto delle righe di
\lstinline{minusline} dove nella colonna $i$-esima è stato sostituito
$1$ in tutte le righe tranne la $i$-esima dove è stato sostituito $0$.
\begin{lstlisting}
  for i = (1:N)
    mask = ones(N,1);
    mask(i) = 0;
    minusplusMOD = minusplus;
    minusplusMOD(:,i)= mask;
    pi2T = pi2T + 2*(prod((minusplusMOD)'))';
  end
\end{lstlisting}

Per la derivata terza la formula peggiora:
\[ \pi ''' (t_k) = 3 \sum _{i\neq k} \sum _{j\neq k, j\neq i} \prod
_{h\neq k, h\neq i, h\neq j} (t_k - t_h) \]

La soluzione adattata per il calcolo è analoga alla precedente
\begin{lstlisting}
  for i = (1:N)
    for j = (1:N)
      if i ~= j
        maski = ones(N,1);
        maski(i) = 0;
        maski(j) = 0;
        maskj = ones(N,1);
        maskj(i) = 0;
        maskj(j) = 0;
        minusplusMOD = minusplus;
        minusplusMOD(:,i)= maski;
        minusplusMOD(:,j)= maskj;
        pi3T = pi3T + 3*(prod((minusplusMOD)'))';
      end
    end
  end
\end{lstlisting}
dove \lstinline{maski} servono ad escludere dalla produttoria i
fattori $(t_k - t_i)$ e $(t_k - t_j)$ e dalla sommatoria le righe
$i$-esime e $j$-esime\footnote{In realtà impostare a zero le due righe
  sia su \lstinline{maski} sia su \lstinline{maskj} è superfluo, ne
  basta solo una delle due}.

Ora che conosciamo le derivate dei polinomi di Lagrange possiamo
calcolare le matrici di differenziazione di primo e secondo grado
utilizzando le formule
\[ d^{(1)} _{j,k} = \left\{
  \begin{matrix}
    \frac{\pi'(t_j)}{(t_j - t_k)\pi'(t_k)} & j\neq k \\
    \frac{\pi''(t_k)}{2\pi'(t_k)} & j = k
  \end{matrix}
\right.
\]
\[ d^{(2)} _{j,k} = \left\{
  \begin{matrix}
    \frac{1}{t_j-t_k}\bra{\frac{\pi''(t_j)}{\pi'(t_k)} - 2 d^{(1)}
      _{j,k} } & j\neq k \\
    \frac{\pi'''(t_k)}{3\pi'(t_k)} & j = k
  \end{matrix}
\right.
\]


\subsection{Implementazione: ciclo principale: calcolo di $T(v_k)$ e dello jacobiano nel punto}

Dopo aver esteso per simmetria il potenziale, risolviamo il problema
diretto (con \lstinline{directSLP_inner1}). A questo punto possiamo
calcolare $T(v_k)$ come differenza tra i primi $M$ autovalori
calcolati e gli autovalori in ingresso.

Per applicare il metodo di Newton dobbiamo calcolare lo Jacobiano di
$T$ nel punto $v_k$. La formula può essere ricavata derivando
l'equazione di Sturm Liouville, infatti dopo alcuni calcoli algebrici
si arriva alla relazione
\begin{equation*}
  y_i ^T \der{V}{v_j} y_i = y_i ^T \der{\lambda _i}{v_j} y_i
\end{equation*}
dove $y_i$ è l'$i$-esimo autovettore relativo all'$i$-esimo autovalore
$\lambda _i$, $v_j$ è il valore del potenziale nel punto $\xi_j$ e $V$
è la matrice che ha sulla diagonale il valore del potenziale calcolato
nei punti di griglia esteso per simmetria.

Da questo si ricava che, utilizzando l'ortonormalità dei $y_i$, si ha
\begin{equation*}
  \der{\lambda _i}{v_j} = 2 ((y_i)_j) ^2
\end{equation*}
dove il fattore moltiplicativo $2$ deriva dal fatto che $v_j$ compare
due volte nella matrice $V$ (perché abbiamo esteso il potenziale con
la simmetria).

Questa formula è implementata in
\begin{lstlisting}
  Ak =  2*(((Yk(2:M+1,1:M))').^2)
\end{lstlisting}
dove dobbiamo ricordarci che, per le condizioni al contorno di
Dirichlet, dobbiamo ignorare i valori del potenziale in $0$

\subsection{Implementazione: ciclo principale: regolarizzazione e
  aggiornamento del potenziale}

Visto il cattivo condizionamento dello Jacobiano $A_k$ si utilizza il
metodo di Tikhonov per regolarizzare il problema 
\begin{equation*}
  \Delta v _k = A_k ^{-1} T(v_k)
\end{equation*}

Per questo passaggio utilizziamo i Regularization Tools di Per
Christian Hansen che si trovano alla pagina
\url{http://www.imm.dtu.dk/~pcha/Regutools/regutools.html}

Per prima cosa calcoliamo la scomposizione in valori singolari
generalizzata dello jacobiano e della matrice di penalizzazione con
l'istruzione
\begin{lstlisting}
  [ WW, SigmaM, XX, VV] = cgsvd(Ak,DiffMat) ;
\end{lstlisting}

Ora possiamo cercare il parametro di ottimizzazione ottimale con
l'istruzione
\begin{lstlisting}
  reg_corner = l_curve(WW,SigmaM,Tk,'Tikh') ;
\end{lstlisting}

Da esperimenti su uno dei casi di prova si vede che questo metodo
sceglie parametri di regolarizzazione troppo grandi e, quindi,
regolarizza troppo. Per questo limitiamo la scelta del paramentro di
regolarizzazione sostituendo la chiamata a \lstinline{l_curve} con
\begin{lstlisting}
  reg_param = logspace(6,-4,600);
  [x,rho,eta] = tikhonov(WW,SigmaM,XX,Tk,reg_param,vk);
  reg_corner = l_corner(rho,eta,reg_param,WW,SigmaM,Tk);
\end{lstlisting}

Una volta ottenuto il parametro otteniamo la soluzione regolarizzata
con il comando
\begin{lstlisting}
  Deltavk = tikhonov(WW,SigmaM,XX,Tk,reg_corner,vk) ;
\end{lstlisting}
che ha risolto il problema
\[
\lstinline{Deltavk} = \arg\min _{x} \pa{ \norm{\lstinline{Ak}x -
    \lstinline{Tk}} ^2 + \lstinline{reg_corner}
  \norm{\lstinline{DiffMat} \pa{ x - \lstinline{vk}}}^2 }
\]

Ora che è disponibile $\Delta v_k$ possiamo aggiornare il valore di
\lstinline{vk} per la prossima iterazione
\begin{lstlisting}
  vk = vk - Deltavk ;
\end{lstlisting}

\subsection{Implemenatazione: fine ciclo e confezionamento dell'output}

Il ciclo viene terminato quando viene raggiunto il numero massimo di
iterazioni consentite \lstinline{Kmax} oppure quando la variazione
\lstinline{Deltavk} è minore di \lstinline{tol * vk}, cioè ci stiamo
spostando ``poco'' dal punto in cui siamo.

Infine il vettore del valore del potenziale nei punti griglia viene
riscalato all'intervallo iniziale ed esteso per simmetria.
\begin{lstlisting}
  q = extender * ((pi/L)^2 * vk ) ;
\end{lstlisting}




\end{document}

